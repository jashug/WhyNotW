
\documentclass[a4paper,UKenglish,cleveref,nameinlink,autoref,thm-restate]{lipics-v2019}
%This is a template for producing LIPIcs articles. 
%See lipics-manual.pdf for further information.
%for A4 paper format use option "a4paper", for US-letter use option "letterpaper"
%for british hyphenation rules use option "UKenglish", for american hyphenation rules use option "USenglish"
%for section-numbered lemmas etc., use "numberwithinsect"
%for enabling cleveref support, use "cleveref"
%for enabling autoref support, use "autoref"
%for anonymousing the authors (e.g. for double-blind review), add "anonymous"
%for enabling thm-restate support, use "thm-restate"

\bibliographystyle{plainurl}% the mandatory bibstyle

\title{Why not W?}

\author{Jasper Hugunin}{Carnegie Mellon University, Pittsburgh PA, USA}{jasper@hugunin.net}{https://orcid.org/0000-0002-1133-5354}{}

\authorrunning{J. Hugunin}

\Copyright{Jasper Hugunin}

\ccsdesc[500]{Theory of computation~Type theory}

\keywords{dependent types, intensional type theory, inductive types, W types}

\relatedversion{} %optional, e.g. full version hosted on arXiv, HAL, or other respository/website
%\relatedversion{A full version of the paper is available at \url{...}.}

\supplement{Tag \texttt{v0.1} of \url{https://github.com/jashug/WhyNotW}}

\acknowledgements{I want to thank Jon Sterling and the anonymous reviewers for their helpful feedback.}

%\nolinenumbers %uncomment to disable line numbering

%\hideLIPIcs  %uncomment to remove references to LIPIcs series (logo, DOI, ...), e.g. when preparing a pre-final version to be uploaded to arXiv or another public repository

%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{John Q. Open and Joan R. Access}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{CVIT 2016}
\EventAcronym{CVIT}
\EventYear{2016}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage{float}
%\floatstyle{boxed} 
%\restylefloat{figure}

\newcommand{\zero}{\mathtt{0}}
\newcommand{\one}{\mathtt{1}}
\newcommand{\bool}{\mathtt{2}}
\newcommand{\true}{\mathtt{tt}}
\newcommand{\false}{\mathtt{ff}}
\newcommand{\codeO}{\mathtt{\hat{O}}}
\newcommand{\codeS}{\mathtt{\hat{S}}}
\newcommand{\U}{\mathtt{U}}

\DeclareMathOperator{\supop}{\mathtt{sup}}
\renewcommand{\sup}[2]{\supop {#1}\:\!{#2}}

\newcommand{\N}{\hyperref[define-N]{\mathbb{N}}}
\newcommand{\preN}{\hyperref[define-preN]{\tilde{\mathbb{N}}}}

\DeclareMathOperator{\case}{\mathtt{case}}
\newcommand{\caset}[2]{\case {#1}\;\mathtt{of}\;\{{#2}\}}

%\newcommand{\casepath}[4]{\case {#1};\mathtt{inl}\;\Id{\mathunderscore}{#2}\;\mathtt{return}\;{#3}\;\mathtt{of}\;\{\refl\mapsto{#4}\}}

\DeclareMathOperator{\W}{\mathtt{W}}

\DeclareMathOperator{\Idop}{\mathtt{Id}}
\newcommand{\Id}[2]{\Idop {#1}\;{#2}}
\newcommand{\IdA}[3]{\Idop_{#1}{#2}\;{#3}}
\newcommand{\refl}{\mathtt{refl}}

\DeclareMathOperator{\inl}{\mathtt{inl}}
\DeclareMathOperator{\inr}{\mathtt{inr}}

\DeclareMathOperator{\fst}{\mathtt{fst}}
\DeclareMathOperator{\snd}{\mathtt{snd}}

\DeclareMathOperator{\canonical}{\hyperref[define-canonical]{\mathtt{canonical}}}

\newcommand{\ISO}{\hyperref[define-ISO]{\mathrm{ISO}}}
\newcommand{\ISS}{\hyperref[define-ISS]{\mathrm{ISS}}}
\newcommand{\IS}{\mathrm{IS}}

\newcommand{\zerO}{\hyperref[define-O]{\mathrm{O}}}
\DeclareMathOperator{\Succ}{\hyperref[define-S]{S}}
\DeclareMathOperator{\recN}{\hyperref[define-recN]{\mathrm{rec\mathbb{N}}}}

\DeclareMathOperator{\nonind}{nonind}
\DeclareMathOperator{\ind}{ind}
\DeclareMathOperator{\nil}{nil}
\DeclareMathOperator{\choice}{choice}
\newcommand{\Code}{\mathrm{Code}}

\newcommand{\Ix}{\mathrm{Ix}}

\DeclareMathOperator{\El}{El}
\DeclareMathOperator{\preEl}{\tilde{El}}
\DeclareMathOperator{\intro}{intro}
\DeclareMathOperator{\rec}{rec}

\DeclareMathOperator{\All}{All}

\newcommand{\splitequiv}{\hyperref[split-equiv]{r}}

\newcommand{\mathquote}[1]{\text{``${#1}$''}}

\DeclareMathOperator{\funext}{\mathtt{funext}}

\newcommand{\funF}{\hyperref[define-F]{F}}
\newcommand{\funG}{\hyperref[define-G]{G}}

\begin{document}

\maketitle

\begin{abstract}
In an extensional setting, $\W$ types are sufficient to construct a broad class of inductive types, but in intensional type theory the standard construction of even the natural numbers does not satisfy the required induction principle. In this paper, we show how to refine the standard construction of inductive types such that the induction principle is provable and computes as expected in intensional type theory without using function extensionality. We extend this by constructing from $\W$ an internal universe of codes for inductive types, such that this universe is itself an inductive type described by a code in the next larger universe. We use this universe to mechanize and internalize our refined construction.
\end{abstract}

\section{Introduction}

In intensional type theory with only type formers $\zero$, $\one$, $\bool$, $\Sigma$, $\Pi$, $\W$, $\Idop$ and $\U$, can the natural numbers be constructed?

The $\W$ type \cite{mltt} captures the essence of induction (that we have a collection of possible cases, and for each case there is a collection of sub-cases to be handled inductively), and in extensional type theory it is straightforward to construct familiar inductive types out of it, including the natural numbers \cite{dybjer-W-encodes-inductive}.
Taking the elements of the two-element type $\bool$ to be $\codeO$ and $\codeS$, we define \begin{equation}\label{define-preN}\preN = \W_{b : \bool} (\caset{b}{\codeO \mapsto \zero, \codeS \mapsto \one}).\end{equation}
(the tilde distinguishes the standard construction from our refined construction of the natural numbers in \cref{construct-N})

However, as is well known \cite{dybjer-W-encodes-inductive,luo-wellordering,mcbride_wtypes,programming-in-MLTT}, in intensional type theory we cannot prove the induction principle for $\preN$ without some form of function extensionality.
The obstacle is in the $\codeO$ case, where we end up needing to prove $P\;f$ for an arbitrary $f : \zero \to \preN$, when we only know $P\;(x\mapsto\caset{x}{})$.

Can this obstacle be avoided?
The answer turns out to be yes; in this paper, we show that refining the standard construction allows the natural numbers and many other inductive types to be constructed from $\W$ in intensional type theory.
\footnote{These results have been formalized in Coq 8.12 \cite{coq-8.12}: see the link to supplementary material in the top matter of this article.}

\paragraph*{Type-theoretic notations and assumptions}

We work in a standard intensional type theory with
dependent function types $\Pi_{a : A}B[a]$ (also written $\forall_{a : A}B[a]$, $(a : A) \to B[a]$, non-dependent version $A \to B$, constructed as $(x \mapsto y[x])$ or $(\lambda x.\;y[x])$),
dependent pair types $\Sigma_{a : A}B[a]$ (also written $(a : A) \times B[a]$, non-dependent version $A \times B$, constructed as $(x, y)$, destructed as $\fst p$, $\snd p$),
finite types $\zero$, $\one$ (with inhabitant $\star$), $\bool$ (with inhabitants $\false$ and $\true$, aliased to $\codeO$ and $\codeS$ when we are talking about constructing the natural numbers),
$\W$ types $\W_{a : A}B[a]$ (constructor $\sup{a}{f}$ for $a : A$ and $f : B[a] \to \W_{a}B[a]$),
identity types $\IdA{A}{x}{y}$ (constructor $\refl$, destruction of $e : \Id{x}{y}$ keeps $x$ fixed and generalizes over $y$ and $e$),
and a universe $\U$.
We define the coproduct $A + B$ as $\sum_{b : \bool}\caset{b}{\false\mapsto A, \true\mapsto B}$, and notate the injections as $\inl$ and $\inr$.

Function extensionality is the principle that $\forall_x\Id{(f\;x)}{(g\;x)}$ implies $\Id{f}{g}$, and uniqueness of identity proofs is the principle that $\IdA{\Id{x}{y}}{p}{q}$ is always inhabited. We do \emph{not} assume either of these principles.

We require strict $\beta$-rules for all type formers, and strict $\eta$ for $\Sigma$ (that $p = (\fst p, \snd p)$) and $\Pi$ (that $f = (x \mapsto f x)$). For convenience we will also assume strict $\eta$ for $\one$ (that $u = \star$).

\section{Constructing \texorpdfstring{$\N$}{â„•} (for real this time)}\label{construct-N}

We run into problems in the $\codeO$ case because we don't know that $f = (x\mapsto\caset{x}{})$ for an arbitrary $f : \zero \to \preN$.
To solve those problems, we will assume them away.
To construct $\N$, we will first define a predicate $\canonical : \preN \to U$ such that $\canonical(\sup{\codeO}{f})$ implies $\Id{(x\mapsto\caset{x}{})}{f}$.
We then let $\N = \Sigma_{x : \preN}\canonical x$ be the canonical elements of $\preN$ (with $\preN$ defined by \cref{define-preN}).
This predicate will be defined by induction on $\W$, so we can start out with \[\canonical (\sup{x}{f}) =\; ? : \U\qquad\text{($x : \bool$, $f : \dots \to \preN$, may use $\canonical (f\; i) : \U$)}.\]
The obvious next thing to do is to split by cases on $x : \bool$:
\begin{gather*}
\canonical (\sup{\codeO}{f}) =\; ? : \U\qquad\text{($f : \zero \to \preN$, may use $\canonical(f\;i)$)},\\
\canonical (\sup{\codeS}{f}) =\; ? : \U\qquad\text{($f : \one \to \preN$, may use $\canonical(f\;i)$)}.
\end{gather*}

We need canonical terms to be \emph{hereditarily} canonical, that is, we want to include the condition that all sub-terms are canonical.
For the $\codeS$ case, thanks to the strict $\eta$ rules for $\one$ and $\Pi$, the types $\canonical(f\;\star)$ and $(i : \one) \to \canonical(f\;i)$ are equivalent; we can use either one.
This will be the only condition we need for the $\codeS$ case, so we can complete this part of the definition:
\[\canonical (\sup{\codeS}{f}) =\canonical(f\;\star).\]

The $\codeO$ case is the interesting one.
The blind translation of ``every sub-term is canonical'' is $(i : \zero) \to \canonical(f\;i)$,
but this leads to the same problem as before: without function extensionality we can't work with functions out of $\zero$.
Luckily, we have escaped the rigid constraints of the $\W$ type former, and have the freedom to translate the recursive condition as simply $\one$.
No sub-terms of zero, no conditions necessary!
\[\canonical (\sup{\codeO}{f}) =\; ? : \U\qquad\text{($f : \zero \to \preN$)}\]

That is all well and good, but we can't forget why we are here in the first place: we need $\Id{(x\mapsto\caset{x}{})}{f}$.
Luckily, there is a hole just waiting to be filled:
\[\canonical (\sup{\codeO}{f}) = \Id{(x\mapsto\caset{x}{})}{f}.\]

\begin{figure}[t]
\fbox{\begin{minipage}{\textwidth}\setlength{\abovedisplayskip}{0pt} % Remove excess vertical space
\begin{gather}
\preN = \W_{b : \bool} (\caset{b}{\codeO \mapsto \zero, \codeS \mapsto \one}) : \U,\nonumber\\
\begin{aligned}
\canonical& : \preN \to \U,\\
\canonical& (\sup{\codeO}{f}) = \Id{(x\mapsto\caset{x}{})}{f},\\
\canonical& (\sup{\codeS}{f}) = \canonical(f\;\star),
\end{aligned}\label{define-canonical}\\
\N = \Sigma_{x : \preN}\canonical x : \U,\label{define-N}\\
\zerO = (\sup{\codeO}{(x\mapsto\caset{x}{})},\refl) : \N,\label{define-O}\\
\Succ = n \mapsto (\sup{\codeS}{(\star \mapsto \fst n)},\snd n) : \N \to \N.\label{define-S}
\end{gather}
\end{minipage}}
\caption{The complete definition of $\N$.}
\end{figure}

\paragraph*{Induction}

Now we are ready for the finale: induction for $\N$ with the right computational behavior.

Assume we are given a type $P[n]$ which depends on $n : \N$, along with terms $\ISO : P[\zerO]$ and $\ISS : \forall_{n : \N}P[n] \to P[\Succ\;n]$. Our mission is to define a term $\recN : \forall_{n : \N}P[n]$. Happily, the proof goes through if we simply follow our nose.

We begin by performing induction on $\fst n : \preN$, and then case on $\codeO$ vs $\codeS$, just like the definition of $\canonical$.
\begin{gather*}
\recN (\sup{\codeO}{f},y) =\; ? : P[(\sup{\codeO}{f},y)]\qquad\text{($f : \zero \to \preN$, $y : \Id{(x\mapsto\caset{x}{})}{f}$)},\\
\recN (\sup{\codeS}{f},y) =\; ? : P[(\sup{\codeS}{f},y)]\qquad\text{($f : \one \to \preN$, $y : \canonical(f\;\star)$)}.\\
\text{(where we may make recursive calls $\recN(f\; i, y')$ for any $i$ and $y'$)}
\end{gather*}

In the $\codeS$ case, $f = (\star \mapsto f\; \star)$ by the $\eta$ rules for $\one$ and $\Pi$, and thus $(\sup{\codeS}{f}, y) = \Succ\;(f\; \star, y)$. We can thus define
\begin{equation*}\recN (\sup{\codeS}{f},y) = \ISS\;(f\;\star, y)\;(\recN(f\;\star, y)).\end{equation*}

The $\codeO$ case is again the interesting one, but it is only a little tricky. We know $\ISO : P[ (\sup{\codeO}{(x\mapsto\caset{x}{})},\refl)]$, and we want $P[(\sup{\codeO}{f},y)]$. But since we have $y : \Id{(x\mapsto\caset{x}{})}{f}$, this is a direct application of the eliminator for $\Idop$.
We thus complete the definition of $\recN$ with
\begin{equation*}\recN (\sup{\codeO}{f},y) = \caset{y}{\refl \mapsto \ISO}.\end{equation*}

Examining the definitions, we can see that as long as we have strict $\eta$ for $\Sigma$ and strict $\beta$ for $\Idop$, $\recN \zerO = \ISO$ and $\recN(\Succ n) = \ISS\;n\;(\recN\;n)$. Thus we have indeed defined the natural numbers with the expected induction principle and computational behavior in terms of the $\W$ type.

\begin{figure}[t]
\fbox{\begin{minipage}{\textwidth}
Given
\begin{gather}
\text{a type $P[n]$ depending on $n : \N$},\\
\ISO : P[\zerO],\label{define-ISO}\\
\ISS : \forall_{n : \N}P[n] \to P[\Succ\;n],\label{define-ISS}
\end{gather}
we have
\begin{gather}
\begin{aligned}
\recN& : \forall_{n : \N}P[n],\\
\recN& (\sup{\codeO}{f},y) = \caset{y}{\refl \mapsto \ISO},\\
\recN& (\sup{\codeS}{f},y) = \ISS\;(f\;\star, y)\;(\recN(f\;\star, y)),
\end{aligned}\label{define-recN}\\
\recN \zerO = \ISO\label{recN-eqO},\\
\recN(\Succ n) = \ISS\;n\;(\recN\;n)\label{recN-eqS}.
\end{gather}
\end{minipage}}
\caption{Induction for $\N$.}
\end{figure}

\begin{theorem}
    The natural numbers can be constructed in intensional type theory with only type formers $\zero$, $\one$, $\bool$, $\Sigma$, $\Pi$, $\W$, $\Idop$ and $\U$, such that the induction principle has the expected computational behavior.
\end{theorem}

\section{The General Case}\label{general-case}
Above, we have refuted a widely held intuition about the expressiveness of intensional type theory with $\W$ as the only primitive inductive type. Once we know we can construct the natural numbers, that we can construct lots of other inductive types is much less surprising.

Nevertheless, for completeness we define below an internal type of codes for inductive types along with the construction from $\W$ types of the interpretation of those codes. For convenience, in this section we assume that we have not just one universe $\U$ but an infinite cumulative tower of universes $\U_0 : \U_1 : \dots : \U_i : \U_{i+1} : \dots$ all closed under $\zero$, $\one$, $\bool$, $\Sigma$, $\Pi$, $\W$, and $\Idop$ such that $A : \U_i$ implies $A : \U_{i+1}$.

The end result is a universe of inductive types which is self-describing, or ``levitating'' in the sense of \cite{levitation}.

\subsection{Inductive Codes}\label{inductive-codes}
We will let $\Code_i : \U_{i+1}$ be the type of codes for inductive types in $\U_i$, and implement it for now as a primitive inductive type. In \cref{bootstrap} we will show how to construct $\Code$ itself from $\W$.

To define $\Code$, we adapt the axiomatization of induction-recursion from \cite{finite-axiom-IR}. Thus $\Code_i$ is generated by the constructors
\[\nil : \Code_i,\quad \nonind : (A : \U_i) \to (A \to \Code_i) \to \Code_i, \quad \ind : \U_i \to \Code_i \to \Code_i.\]
Looking at $\U_i$ as the usual category of types and functions, a code $A : \Code_i$ defines an endofunctor $\funF_A : \U_i \to \U_i$ defined by recursion on $A$ by
\begin{gather}
F_{\nil}\;X = \one,\label{define-F}\\
F_{\nonind(A,B)}\;X = \Sigma_{a : A} F_{(B\;a)}\; X,\\
F_{\ind(\Ix, B)}\;X = (\Ix \to X) \times F_{B}\; X.
\end{gather}

\begin{example}We can define a code for the natural numbers as \[\mathquote{\N} = \nonind(2, b \mapsto \caset{b}{\codeO \mapsto \nil, \codeS\mapsto \ind(1, \nil)}) : \Code_0.\]
\end{example}

Each code also defines a polynomial functor $G_A\;X = \Sigma_{s : S_A} (P_A\;s \to X)$, which is what is used in the standard construction:
\begin{align}
&S_{\nil} = 1 & &P_{\nil}\;\star = 0\label{define-G}\\
&S_{\nonind(A,B)} = \Sigma_{a : A} S_{(B\;a)} & &P_{\nonind(A, B)}\;(a,b) = P_{(B\;a)}\;b \\
&S_{\ind(\Ix, B)} = S_B & &P_{\ind(\Ix, B)}\;b = \Ix + P_B\;b.\\
&G_A\;X = \Sigma_{s : S_A} (P_A\;s \to X) & &\preEl A = \W_{s : S_A}P_A.
\end{align}
The idea here is that $S_A$ collects up all the non-inductive data, and then $P_A$ counts the number of inductive sub-cases.

There is an easy-to-define natural transformation $\epsilon : \funF \Rightarrow \funG$, and it even has a left inverse on objects, but without function extensionality $\epsilon$ does not have a right inverse (roughly speaking, $\epsilon$ is not surjective); there are usually terms $g : \funG\;X$ not in the image of $\epsilon$. This is exactly the problem we ran into in the case of the natural numbers: the map $(\star \mapsto (x \mapsto \caset{x}{})) : 1 \to (0 \to X)$ is not surjective.
(The above $S$, $P$, and $\epsilon$ roughly correspond to Lemma 3 in \cite{dybjer-W-encodes-inductive})

The last component we need is $\All_A\;s : (Q : P_A\;s \to \U_j) \to \U_j$ (for universe level $j\geq i$), the quantifier ``holds at every position'' (a refinement of $\forall_p, Q\;p$):
\begin{gather}
\All_{\nil}\star\;Q = \one,\\
\All_{\nonind(A,B)}(a,b)\;Q = \All_{(B\;a)}b\;Q,\\
\All_{\ind(\Ix, B)}b\;Q = (\forall_i,Q\;(\inl i)) \times \All_{B}b\;(Q \circ \inr).
\end{gather}

Noting that $\snd (\epsilon\; t) : P\;(\fst (\epsilon\;t)) \to X$ enumerates the sub-terms of $t : \funF\;X$, we find that $\All (Q \circ \snd (\epsilon\;t))$ lifts a predicate $Q : X \to \U_j$ to a predicate over $t : \funF\;X$.

\begin{lemma}\label{split-equiv}There is an equivalence $\splitequiv$ (\`a la Voevodsky, a function with contractible fibers) \begin{equation}
\splitequiv : \funF\;(\Sigma_{x : X}C\;x) \simeq \Sigma_{(t : \funF\;X)}\All (C\circ \snd (\epsilon\;t)).
\end{equation}
\end{lemma}

\begin{proof}
Follows easily by induction on the code $A$. We use equivalences \`a la Voevodsky as a concrete definition of coherent equivalences, which are the ``right'' way to define type equivalence in the absence of UIP.
\end{proof}

\subsection{The General Construction}
We are finally ready to define the true construction of inductive types $\El : \Code \to \U_i$. As with natural numbers, we define a ``canonicity'' predicate on $\preEl A$, which says that ``all subterms are canonical, and this node is in the image of $\epsilon$''.
This translates as:
\begin{equation}
\canonical (\sup{s}{f}) = \All (\canonical \circ f) \times (t : \funF\;(\preEl A)) \times \IdA{\funG\;(\preEl\;A)}{(\epsilon\; t)}{(s, f)} : \U_i,\end{equation}
and thus we finally have \begin{equation}\El\;A = \Sigma_{x : \preEl A} \canonical x.\end{equation}
For the constructors, we expect to have $\intro : \funF\;(\El A) \to \El A$, which we define by
\begin{equation}
\intro x = (\supop\;(\epsilon\;(\fst\;(\splitequiv\;x))),(\snd(\splitequiv\;x),\fst\;(\splitequiv\;x),\refl)).
\end{equation}
using the equivalence $\splitequiv$ from \cref{split-equiv} to split $x : \funF\;(\El A)$ into $\fst(\splitequiv\;x) : \funF\;(\preEl A)$ and $\snd(\splitequiv\;x) : \All(\canonical \circ \snd(\epsilon\;\fst\;(\splitequiv\;x)))$.

\subsection{General Induction}
When we go to define the induction principle for $\El A$, we are given $P : \El A \to \U_j$ for some $j \geq i$ and the induction step $\IS : \forall_{(x : F\;(\El A))}\All(P \circ \snd(\epsilon\;x)) \to P\;(\intro x)$, and want to define $\rec : \forall_{(x : \El A)}P\;x$. The definition proceeds by induction on $\fst x$:
\[\rec(\sup{s}{f},(h,t,e)) ={} ? : P\;(\sup{s}{f},(h,t,e))\qquad h : \All(\canonical \circ f) \quad  e : \Id{(\epsilon \;t)}{(s,f)},\] and we have induction hypothesis $H = p \mapsto c \mapsto \rec(f\;p,c) : \Pi_p\Pi_c P\;(f\;p,c)$. Next, we destruct the identity proof $e$, generalizing over both $h$ and $H$, leaving us with
\[\rec(\supop(\epsilon\;t),(h,t,\refl)) ={} ? : P\;(\supop(\epsilon\;t),(h,t,\refl)),\] for $t : \funF\;(\preEl A)$, $h : \All(\canonical\circ\snd(\epsilon\;t))$, and $H : \Pi_p\Pi_c P\;(\snd(\epsilon\;t)\;p,c)$. The last step to bring us in line with the definition of $\intro$ is to use the equivalence from \cref{split-equiv} to replace $(t, h)$ with $\splitequiv\;x$ for some $x : \funF\;(\El A)$, leaving us with
\[\rec(\supop(\epsilon\;(\fst(\splitequiv\;x))),(\snd(\splitequiv\;x),\fst(\splitequiv\;x),\refl)) ={} ? : P\;(\intro x)\]
and induction hypothesis $H : \Pi_p\Pi_c P\;(\snd(\epsilon\;(\fst(\splitequiv\;x)))\;p,c)$. We can then apply $\IS$, but that leaves us with an obligation to prove $\All (P\circ\snd(\epsilon\;x))$. Fortunately, it is easy to show by induction on the code $A$ that our hypothesis $H$ is sufficient to dispatch this obligation.

This completes the definition of the induction principle, and it can be observed on concrete examples like the natural numbers to have the expected computational behavior. We can also prove a propositional equality $\Id{(\rec(\intro x))}{(\IS\;x\;(\rec\circ \snd(\epsilon\;x)))}$ witnessing the expected computation rule, and observe on concrete examples that this witness computes to reflexivity. The details of this construction have all been formalized in Coq.

\subsection{Bootstrapping}\label{bootstrap}
In \cref{inductive-codes} we postulated the type $\Code_i$ to be a primitive inductive type, which leads to the question of whether the general construction we have proposed is \emph{really} constructing inductive types out of $\W$ or whether it is making sneaky use of the inductive structure of $\Code_i$ to perform the construction.

As a first observation, $\Code_i : \U_{i+1}$ while $\El : \Code_i \to \U_i$, thus $\Code_i$ can't appear as data in $\El A$: it is too big! However, this argument doesn't show that we can completely eliminate $\Code_i$ from the construction.

Next, we observe that the inductive type $\Code_i$ itself has a code $\mathquote{\Code_i} : \Code_{i+1}$:
\begin{align*}
\mathquote{\Code_i} ={}& \nonind((1+\U_i)+\U_i,t \mapsto \case t\;\mathtt{of}\;\{\\
&\quad \inl(\inl\star) \mapsto \nil,&&\text{(case $\nil$)} \notag\\
&\quad \inl(\inr A) \mapsto \ind(A,\nil),&&\text{(case $\nonind$)} \notag\\
&\quad \inr \Ix \mapsto \ind(1,\nil),&&\text{(case $\ind$)} \notag\\
&\notag\}).
\end{align*}

Then we can propose to define $\Code_i = \El \mathquote{\Code_i}$, but this is a circular definition: we define $\Code_i$ by using recursion on $\Code_{i+1}$. What we really want, and in some ways should be able to expect, is that $\El\mathquote{\Code_i}$ \emph{computes} to a normal form which no longer mentions $\Code$ but is expressed purely in terms of $\W$. We could then tie the knot by defining $\Code_i$ to be what $\El \mathquote{\Code_i}$ \emph{will compute to}, once we have defined $\El$.

There is just one minor, rather technical problem to resolve, which is that currently $\El$ (which is defined by recursion on codes) gets stuck on $\El (\caset{t}{\dots})$ which is used to branch on constructor tags;
we are missing some sort of commuting conversion \cite[section 10]{girard-proofs-and-types}.
Fortunately, this problem is easy to work around by reifying the operation of branching on constructor tags as part of $\Code$. We add another constructor
\begin{equation}
\choice : \Code_i \to \Code_i \to \Code_i,\qquad \funF_{\choice(A,B)}\;X = F_A\;X + F_B\;X
\end{equation}
which encodes the simple binary sum of functors, specializing the dependent sum of functors $\nonind(2,b\mapsto\caset{b}{\dots})$ (but with all proofs essentially the same). With this in hand, we can define
\begin{align}
\mathquote{\Code_i} ={}& \choice(\choice(\\
&\quad\nil,&\text{(case $\nil$)}\notag\\
&\quad\choice(\notag\\
&\qquad\nonind(\U_i,A\mapsto \ind(A,\nil)),&\text{(case $\nonind$)}\notag\\
&\qquad\ind(1,\ind(1,\nil)))),&\text{(case $\choice$)}\notag\\
&\quad\nonind(\U_i,\Ix \mapsto \ind(1,\nil))).&\text{(case $\ind$)}\notag
\end{align}

With this adjustment, the structure of the code is not hidden inside $\case$, and the computation of $\El\mathquote{\Code_i}$ proceeds to completion without becoming stuck, resulting in a term which does not mention $\Code$ at all. From there, we can define $\El$ such that $\El\mathquote{\Code_i} = \Code_i$, as in \cite{levitation} but with no invisible cables, just the $\W$ type.
\begin{theorem}
    In intensional type theory with type formers $\zero$, $\one$, $\bool$, $\Sigma$, $\Pi$, $\W$, $\Idop$ and an infinite tower of universes $\U_i$, we can construct terms $\Code_i : \U_{i+1}$ and $\El : \Code_i \to \U_i$ such that $\El A$ is an inductive type, and we can also construct terms $\mathquote{\Code_i} : \Code_{i+1}$ such that $\El\mathquote{\Code_i} = \Code_i$. Furthermore, $\Code_i$ is not trivial: it contains codes for natural numbers, lists, binary trees, and many other inductive types, including inductive types such as $\W$ that have infinitary inductive arguments.
\end{theorem}

\section{Discussion}

\subsection{Composition}
Being codes for functors, one may ask if $\Code_i$ is closed under composition of functors? As with the codes for inductive-recursive types we have modified, without function extensionality we do not appear to have composition (for similar reasons as considered in \cite{variations-IR}). Indeed, experiments suggest that the general construction of a class of inductive types closed under composition of the underlying functors essentially requires function extensionality. Even worse, to get definitional computation rules for the resulting inductive types, all our attempts have required that transporting over $\funext(x\mapsto \refl)$ computes to the identity, a property which not even cubical type theory \cite{cchm-cubical} satisfies (it is satisfied, however, by observational type theory \cite{observational-type-theory}). Thus, we do not know how to combine a class of inductive types closed under composition constructed from the $\W$ type as we have in \cref{general-case} with the the principle of Univalence \cite{hott-book} while maintaining good computational behavior.

We do however wish to emphasize that the construction in \cref{general-case} (which is not closed under composition) is completely compatible with Univalence, and could be implemented in cubical type theory as long as an identity type with strict $\beta$ rule is used.

\subsection{Canonicity}
Despite being constructed from $W$ types, our natural numbers enjoy the canonicity property (that for every closed term $n$ of type $\N$, either $n = \zerO$ or $n = \Succ m$ for some closed $m : \N$), at least as long as $\bool$ and $\Idop$ enjoy canonicity (closed $b : \bool$ implies $b = \codeO$ or $b = \codeS$, and closed $e : \Id{x}{y}$ implies $e = \refl$ and $x = y$). The trick is that when we have some representation of zero, it looks like $(\sup{\codeO}{f},e)$, where $e$ is a closed term of type $\Id{(x\mapsto\caset{x}{})}{f}$, and thus by canonicity for $\Idop$, this must be $(\sup{\codeO}{(x\mapsto\caset{x}{})},\refl) = \zerO$.

However, in a situation like cubical type theory where function extensionality holds, $\Idop$ no longer enjoys canonicity, and neither does our construction of the natural numbers.

\subsection{Problems}
What are the problems with using this construction as the foundation for inductive types in a proof assistant? While we have shown bare possibility, this is not an obviously superior solution when compared to the inductive schemes present in proof assistants today.

The construction is complex, which has the possibility of confusing unification and other elaboration algorithms. While the reduction behavior simulates the expected such, the reduction engine has to make many steps to simulate one step of a primitive inductive type, which can lead to a large slowdown. As an example, we observed the general construction slow down from seconds to check to half an hour when replacing primitive inductive types the bootstrapped definition of $\Code$. Understanding exactly why this slowdown happens and how to alleviate it is an important question to be answered before attempting to apply this construction in practice.

There are also some (fairly esoteric) limitations to the expressivity of this construction. Nested inductive types such as $\mathtt{Inductive}\;\mathtt{tree} := \mathtt{node} : \mathtt{list}\;\mathtt{tree} \to \mathtt{tree}$ do not appear to be constructible, nor do mutual inductive types landing in a mixture of impredicative and predicative sorts at different levels, and nor do inductive-inductive types.

\subsection{Setoids}
In \cite{palmgren2019setoids}, Palmgren uses W types to construct a setoid model of extensional type theory in intensional type theory, including the natural numbers. In contrast, we have different goals (we are not concerned with extensional type theory), and our construction has different properties: we construct the natural numbers as a set not a setoid, with definitional computation rules and canonicity rather than working only up to an extensional setoid notion of equality. Other work on setoid models includes \cite{hoffman-thesis} and \cite{altenkirch-exteq}.

\subsection{Conclusion}

We have shown that intensional type theory with $\W$ and $\Idop$ types is more expressive than was previously believed. It supports not only the natural numbers, but a whole host of inductive types, generated by an internal type of codes, which is itself an inductive type coded for by itself (one universe level up). This brings possibilities for writing generic programs acting on inductive types internally (like in \cite{dybjer-generic}), and perhaps simplifies the general study of extensions of intensional type theory: once you know $\W$ works, you know lots of inductive types work.

%Since intensional type theory forms the kernel of popular proof assistants such as Coq and Agda, understanding how to simplify intensional type theory has the potential to lead to simpler, more flexible, and/or easier to use proof assistants.

Thus we return to the titular question: why not use $\W$ as the foundation of inductive types, for example in a proof assistant like Coq or Agda? Equipped with this result, one can no longer say that it is impossible.

%%
%% Bibliography
%%

%% Please use bibtex, 

\bibliography{whynotw}

\appendix

\end{document}
